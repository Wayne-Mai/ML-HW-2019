{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train=pd.read_csv('adult.data',header=None,delim_whitespace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DesicionTree:\n",
    "    \n",
    "    def __init__(self,train,maxDepth=14,valNum=1000):\n",
    "        self.maxDepth=maxDepth\n",
    "        self.train=train.replace([' ?'],np.nan)\n",
    "        self.train[15]=1        # Column 15 represents the weights of data\n",
    "        self.val=self.train.sample(n=1000,random_state=0).dropna()\n",
    "        #self.val=self.train.iloc[:valNum,:].dropna()\n",
    "        self.dsctCol=[1,3,5,6,7,8,9,13]\n",
    "        self.ctnsCol=[0,4,10,11,12]\n",
    "        self.attributes=['age','workclass','fnlwgt','education','education-num',\n",
    "            'marital-status','occupation','relationship','race','sex',\n",
    "            'capital-gain','capital-loss','hours-per-week','native-country']\n",
    "        self.dsctDict={}\n",
    "        self.ctnsMean={}\n",
    "        knownTrain=train.dropna()\n",
    "        for col in self.dsctCol:\n",
    "            self.dsctDict[self.attributes[col]]=knownTrain[col].value_counts()\n",
    "        for col in self.ctnsCol:\n",
    "            self.ctnsMean[self.attributes[col]]=knownTrain[col].mean()\n",
    "        self.classDict=train[14].value_counts()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def allSameClass(self,dataset,attributes):\n",
    "        currentClass=''\n",
    "        for index,row in dataset.iterrows():\n",
    "            if row[14]!=currentClass:\n",
    "                if currentClass!='':\n",
    "                    return False\n",
    "                else:\n",
    "                    currentClass=row[14]\n",
    "\n",
    "        return currentClass\n",
    "    \n",
    "    def allSameAttribute(self,dataset,attributes):\n",
    "\n",
    "        sameAttribute={col:dataset.iloc[0][col] for col in attributes}\n",
    "        \n",
    "        for index,row in dataset.iterrows():\n",
    "            for col in attributes:\n",
    "                if row[col]!=sameAttribute[col]:\n",
    "                    return False\n",
    "                \n",
    "        # show rarely happen\n",
    "        return True\n",
    "    \n",
    "    def mostCommonClass(self,dataset):\n",
    "        classDct=dataset[14].value_counts()       \n",
    "        return classDct.index[0]\n",
    "    \n",
    "    \n",
    "    def entropy(self,classDict):\n",
    "        \n",
    "        pClassDict=classDict.divide(classDict.sum())\n",
    "        ent=0.0\n",
    "        for className in self.classDict.index:\n",
    "            if className in pClassDict.index and pClassDict[className]!=0: \n",
    "                ent+=pClassDict[className]*np.log2(pClassDict[className])\n",
    "        return -1*ent\n",
    "    \n",
    "        \n",
    "        \n",
    "    def bestAttribute(self,dataset,attributes):\n",
    "        infoGain=-float('inf')\n",
    "        best_a,best_t=None,None\n",
    "        temp_t=0\n",
    "        \n",
    "        \n",
    "        for a in attributes:\n",
    "            knownDataset=dataset.dropna()\n",
    "            rho=knownDataset[15].sum()/dataset[15].sum() \n",
    "            knownEntropy=self.entropy(knownDataset[14].value_counts())\n",
    "        \n",
    "            if a in self.dsctCol:    # Discrete var\n",
    "                \n",
    "                subEntropy=0.0\n",
    "                for dsctValue in self.dsctDict[self.attributes[a]].index:\n",
    "                    tempDataset=knownDataset[knownDataset[a]==dsctValue]\n",
    "                    subEntropy+=(tempDataset[15].sum()/knownDataset[15].sum())*\\\n",
    "                                self.entropy(tempDataset[14].value_counts())\n",
    "                \n",
    "                gain=rho*(knownEntropy-subEntropy)\n",
    "            \n",
    "            elif a in self.ctnsCol:    # Continuous var\n",
    "                \n",
    "                gain=-float('inf')\n",
    "                tempCol=dataset[a].drop_duplicates().sort_values()\n",
    "                if tempCol.size!=1:\n",
    "                    tempT=[(tempCol.iloc[i]+tempCol.iloc[i+1])/2 \n",
    "                           for i in range(tempCol.size-1)]\n",
    "                else:\n",
    "                    tempT=tempCol.tolist()\n",
    "                    \n",
    "                for t in tempT:\n",
    "                    subEntropy=0.0\n",
    "                    tempHiDataset=knownDataset[knownDataset[a]>t]\n",
    "                    tempLoDataset=knownDataset[knownDataset[a]<=t]\n",
    "                    subEntropy+=(tempHiDataset[15].sum()/knownDataset[15].sum()*\\\n",
    "                                self.entropy(tempHiDataset[14].value_counts()))\n",
    "                    subEntropy+=(tempLoDataset[15].sum()/knownDataset[15].sum()*\\\n",
    "                                self.entropy(tempLoDataset[14].value_counts()))\n",
    "                    if pd.isna(rho)==False:\n",
    "                        tempGain=rho*(knownEntropy-subEntropy)\n",
    "                    else:\n",
    "                        tempGain=knownEntropy-subEntropy\n",
    "                    \n",
    "                    if tempGain>gain:\n",
    "                        gain=tempGain\n",
    "                        temp_t=t\n",
    "            \n",
    "            \n",
    "            if gain>infoGain:\n",
    "                infoGain,best_a=gain,a\n",
    "                best_t=temp_t\n",
    "      \n",
    "        return best_a,best_t\n",
    "    \n",
    "    def prePruning(self,dataset,best_a,best_t):\n",
    "        \n",
    "        sub_nodes={}\n",
    "        \n",
    "        if best_a in self.dsctCol:    \n",
    "            \n",
    "            for dsctValue in self.dsctDict[self.attributes[best_a]].index:\n",
    "                subDataset=dataset[dataset[best_a]==dsctValue]\n",
    "                if subDataset.empty:\n",
    "                    sub_nodes[self.attributes[best_a]+':'+dsctValue]=\\\n",
    "                        self.classDict.index[0]\n",
    "                else:\n",
    "                    sub_nodes[self.attributes[best_a]+':'+dsctValue]=\\\n",
    "                        self.mostCommonClass(subDataset)\n",
    "            \n",
    "        elif best_a in self.ctnsCol:\n",
    "            \n",
    "            # attributes.remove(best_a)\n",
    "            subHiDataset=dataset[dataset[best_a]>best_t]\n",
    "            \n",
    "            if subHiDataset.empty:\n",
    "                sub_nodes[self.attributes[best_a]+':>'+str(best_t)]=\\\n",
    "                    self.classDict.index[0]\n",
    "            else:\n",
    "                sub_nodes[self.attributes[best_a]+':>'+str(best_t)]=\\\n",
    "                    self.mostCommonClass(subHiDataset)\n",
    "           \n",
    "            subLoDataset=dataset[dataset[best_a]<=best_t]\n",
    "            if subLoDataset.empty:\n",
    "                sub_nodes[self.attributes[best_a]+':<='+str(best_t)]=\\\n",
    "                    self.classDict.index[0]\n",
    "            else:\n",
    "                sub_nodes[self.attributes[best_a]+':<='+str(best_t)]=\\\n",
    "                    self.mostCommonClass(subLoDataset)\n",
    "        \n",
    "        # Validation\n",
    "        \n",
    "        bfCommon=self.mostCommonClass(dataset)    # bf means before\n",
    "        bfCorrect=0                               # af meas after\n",
    "        afCorrect=0\n",
    "        \n",
    "        # Avoid useless iterations, when whether prune or not the prediction\n",
    "        # is the same.\n",
    "        noDiff=True\n",
    "        for value in sub_nodes.values():\n",
    "            if value!=bfCommon:\n",
    "                noDiff=False\n",
    "                break\n",
    "        if noDiff:\n",
    "            return False        \n",
    "        \n",
    "        for index,row in self.val.iterrows():\n",
    "            if row[14]==bfCommon:\n",
    "                bfCorrect+=1\n",
    "            if row[14]==self.forward(row,sub_nodes):\n",
    "                afCorrect+=1\n",
    "        \n",
    "\n",
    "        if bfCorrect>afCorrect:\n",
    "            return bfCommon\n",
    "        return False\n",
    "        \n",
    "    \n",
    "    def treeGenerate(self,dataset,attributes,curDepth=0):\n",
    "        \n",
    "        \n",
    "        # If remain dataset in the same class\n",
    "        isSame=self.allSameClass(dataset,attributes)\n",
    "        if isSame!=False:\n",
    "            return isSame\n",
    "        \n",
    "        if len(attributes)==0 or self.allSameAttribute(dataset,attributes) or curDepth>self.maxDepth:\n",
    "                return self.mostCommonClass(dataset)\n",
    "        \n",
    "        \n",
    "        best_a,best_t=self.bestAttribute(dataset,attributes)\n",
    "        # print(\"Best a and best t at this loop : \"+str(best_a)+\" \"+str(best_t))\n",
    "        \n",
    "        \n",
    "        isPruning=self.prePruning(dataset,best_a,best_t)\n",
    "        if isPruning!=False:\n",
    "            return isPruning\n",
    "        \n",
    "        \n",
    "        sub_nodes={}\n",
    "        unknownDataset=dataset[dataset[best_a].isnull()]\n",
    "        \n",
    "        if best_a in self.dsctCol:    # Choose a discrete node\n",
    "            attributes.remove(best_a)  # Note : only in dsct we do this\n",
    "            \n",
    "            \n",
    "            for dsctValue in self.dsctDict[self.attributes[best_a]].index:\n",
    "                tempDataset=dataset[dataset[best_a]==dsctValue]\n",
    "                r=tempDataset[15].sum()/dataset[15].sum()\n",
    "                unknownDataset.loc[:,15]*=r\n",
    "                \n",
    "                subDataset=tempDataset.append(unknownDataset)\n",
    "                if subDataset.empty:\n",
    "                    sub_nodes[self.attributes[best_a]+':'+dsctValue]=\\\n",
    "                        self.classDict.index[0]\n",
    "                else:\n",
    "                    sub_nodes[self.attributes[best_a]+':'+dsctValue]=\\\n",
    "                        self.treeGenerate(subDataset,attributes,curDepth+1)\n",
    "                unknownDataset.loc[:,15]/=r\n",
    "            \n",
    "        elif best_a in self.ctnsCol:\n",
    "            \n",
    "            # attributes.remove(best_a)\n",
    "            # knownDataset=dataset.dropna()\n",
    "            \n",
    "            tempHiDataset=dataset.loc[dataset[best_a]>best_t]\n",
    "            r=tempHiDataset[15].sum()/dataset[15].sum()\n",
    "            unknownDataset.loc[:,15]*=r\n",
    "            subHiDataset=tempHiDataset.append(unknownDataset)\n",
    "            if subHiDataset.empty:\n",
    "                sub_nodes[self.attributes[best_a]+':>'+str(best_t)]=\\\n",
    "                    self.classDict.index[0]\n",
    "            else:\n",
    "                sub_nodes[self.attributes[best_a]+':>'+str(best_t)]=\\\n",
    "                    self.treeGenerate(subHiDataset,attributes,curDepth+1)\n",
    "                \n",
    "            unknownDataset.loc[:,15]/=r\n",
    "            \n",
    "            tempLoDataset=dataset[dataset[best_a]<=best_t]\n",
    "            r=tempLoDataset[15].sum()/dataset[15].sum()\n",
    "            unknownDataset.loc[:,15]*=r\n",
    "            subLoDataset=tempLoDataset.append(unknownDataset)\n",
    "            if subLoDataset.empty:\n",
    "                sub_nodes[self.attributes[best_a]+':<='+str(best_t)]=\\\n",
    "                    self.classDict.index[0]\n",
    "            else:\n",
    "                sub_nodes[self.attributes[best_a]+':<='+str(best_t)]=\\\n",
    "                    self.treeGenerate(subLoDataset,attributes,curDepth+1)\n",
    "            \n",
    "        # print(sub_nodes)      \n",
    "        return sub_nodes\n",
    "        \n",
    "    def forward(self,row,sub_tree):\n",
    "        # Reach the end of desicion tree\n",
    "        if isinstance(sub_tree,str):\n",
    "            return sub_tree\n",
    "        \n",
    "        first_key=next(iter(sub_tree))\n",
    "        attribute_value=first_key.split(':')\n",
    "        a=self.attributes.index(attribute_value[0])        \n",
    "        \n",
    "        if a in self.dsctCol:\n",
    "            \n",
    "            if pd.isna(row[a]):\n",
    "                row[a]=self.dsctDict[self.attributes[a]].index[0]\n",
    "            \n",
    "            for key in sub_tree.keys():\n",
    "                \n",
    "                if row[a] in key:\n",
    "                    # print(row[a])\n",
    "                    return self.forward(row,sub_tree[key])\n",
    "            \n",
    "        elif a in self.ctnsCol:\n",
    "            \n",
    "            if pd.isna(row[a]):\n",
    "                row[a]=self.ctnsMean[self.attributes[a]]\n",
    "                \n",
    "            for key in sub_tree.keys():\n",
    "                if '>' in key:\n",
    "                    hiKey=key\n",
    "                elif '<' in key:\n",
    "                    loKey=key\n",
    "            \n",
    "            t=float(hiKey.split('>')[-1])\n",
    "            if row[a]<=t:\n",
    "                return self.forward(row,sub_tree[loKey])\n",
    "            return self.forward(row,sub_tree[hiKey])\n",
    "        \n",
    "    def predict(self,test,decisionTree):    # test is a dataframe\n",
    "        test=test.replace([' ?'],np.nan)\n",
    "        # print(test)\n",
    "        correct=0\n",
    "        for index,row in test.iterrows():\n",
    "            res=self.forward(row,decisionTree)\n",
    "            if row[14]==res+'.':\n",
    "                correct+=1\n",
    "        \n",
    "        print(\"Correct:\",correct)\n",
    "        print(\"Total:\",test.shape[0])\n",
    "        print(\"Ratio:\",correct/test.shape[0])\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree=DesicionTree(train)\n",
    "decisionTree=tree.treeGenerate(tree.train,tree.dsctCol+tree.ctnsCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 13731\n",
      "Total: 16281\n",
      "Ratio: 0.8433757140224802\n"
     ]
    }
   ],
   "source": [
    "test=pd.read_csv('adult.test',header=None,sep=',')\n",
    "tree.predict(test,decisionTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(decisionTree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
