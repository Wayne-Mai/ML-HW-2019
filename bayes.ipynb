{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readWaterMelon():\n",
    "    df=pd.read_csv('watermelon3.csv',delimiter=',')\n",
    "    df.iloc[:,-1] = pd.Categorical(df.iloc[:,-1])\n",
    "    df['code'] = df.iloc[:,-1].cat.codes\n",
    "    df['code']=df['code'].astype(str)\n",
    "    \n",
    "    df=df.drop([df.columns[0],df.columns[-2]],axis=1)\n",
    "    \n",
    "    sfolder = StratifiedKFold(n_splits=4,random_state=0)\n",
    "    sfolder.get_n_splits(df)\n",
    "    train_index, test_index=next(sfolder.split(df,df.iloc[:,-1].values))\n",
    "    train_df,val_df=df.iloc[train_index],df.iloc[test_index]\n",
    "    \n",
    "    dsct=[]\n",
    "    ctns=[]\n",
    "    for col in df.columns[:-1]:\n",
    "        if df[col].dtype=='object':\n",
    "            dsct.append(col)\n",
    "        else:\n",
    "            ctns.append(col)\n",
    "    return df,dsct,ctns\n",
    "#     return train_df,val_df,dsct,ctns\n",
    "\n",
    "def get_val_df(columns):\n",
    "    val_df=pd.DataFrame(columns=columns)\n",
    "    val_df.loc[0]=['青绿','蜷缩','浊响','清晰','凹陷','硬滑',0.691,0.460,np.nan]\n",
    "    return val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    \n",
    "    def __init__(self,args={}):\n",
    "        self.args=args\n",
    "    \n",
    "    def train(self,df,dsct,ctns):\n",
    "        label_key=df.iloc[:,-1].value_counts()\n",
    "        \n",
    "        self.args['dsct']=dsct\n",
    "        self.args['ctns']=ctns\n",
    "        self.args['labels']=label_key\n",
    "        self.args['bayes']={}\n",
    "        \n",
    "        # p(c), prior probability\n",
    "        for label,count in label_key.items():\n",
    "            self.args['bayes'][label]=(count+1)/(df.shape[0]+len(label_key))\n",
    "        \n",
    "        # p(c/x_i), with Lapras smooth\n",
    "        \n",
    "        \n",
    "        for attr in dsct:\n",
    "            attrColumn=df[attr]\n",
    "            attr_N=len(attrColumn.value_counts())\n",
    "            self.args['bayes'][attr]={}\n",
    "            for label in label_key.keys():\n",
    "                temp=df[df['code']==label][attr].value_counts()\n",
    "                self.args['bayes'][attr][label]={}\n",
    "                for value,count in temp.items():\n",
    "                    self.args['bayes'][attr][label][value]=(count+1)/(label_key[label]+attr_N)\n",
    "        \n",
    "        for attr in ctns:\n",
    "            self.args['bayes'][attr]={}\n",
    "            for label in label_key.keys():\n",
    "                attrColumn=df[df['code']==label][attr]\n",
    "                attrStd=attrColumn.std()\n",
    "                attrMean=attrColumn.mean()\n",
    "                self.args['bayes'][attr][label]=(attrMean,attrStd)\n",
    "        \n",
    "        \n",
    "    def predict(self,test):\n",
    "        total=test.shape[0]\n",
    "        correct=0\n",
    "        for xi in range(total):\n",
    "            probs={}\n",
    "            \n",
    "            for label in self.args['labels'].keys():\n",
    "                curScore=self.args['bayes'][label]\n",
    "                \n",
    "                # calculate discrete attributes\n",
    "                for attr in self.args['dsct']:\n",
    "                    curScore*=self.args['bayes'][attr][label][test[attr].iloc[xi]]\n",
    "            \n",
    "                # calculate continuous attributes, ...[1] is variance, while [0] is class-wise mean of attr\n",
    "                for attr in self.args['ctns']:\n",
    "                    curScore*=1/(np.sqrt(2*np.pi)*self.args['bayes'][attr][label][1])*\\\n",
    "                                np.exp(-(test[attr].iloc[xi]-self.args['bayes'][attr][label][0])**2/\n",
    "                                           (2*(self.args['bayes'][attr][label][1])**2))\n",
    "                probs[label]=curScore\n",
    "        return probs\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 7.96801546535171e-05, '1': 0.026762967462757723}\n"
     ]
    }
   ],
   "source": [
    "df,dsct,ctns=readWaterMelon()\n",
    "val_df=get_val_df(df.columns)\n",
    "model=NaiveBayes()\n",
    "model.train(df,dsct,ctns)\n",
    "print(model.predict(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AODE:\n",
    "    \n",
    "    def __init__(self,args={}):\n",
    "        self.args=args\n",
    "    \n",
    "    def train(self,df,dsct,ctns):\n",
    "        \"\"\"\n",
    "        Note: for convenience, we only count for discrete attributes this time.\n",
    "        \"\"\"\n",
    "        label_key=df.iloc[:,-1].value_counts()\n",
    "        \n",
    "        self.args['dsct']=dsct\n",
    "        self.args['ctns']=ctns\n",
    "        self.args['labels']=label_key\n",
    "        self.args['bayes']={}\n",
    "        \n",
    "        \n",
    "        # p(c,xi)\n",
    "        for label in label_key.keys():\n",
    "            curSubset=df[df['code']==label]\n",
    "            self.args['bayes'][label]={}\n",
    "            for attr in dsct:\n",
    "                self.args['bayes'][label][attr]={}\n",
    "                attrCount=df[attr].value_counts()\n",
    "                attr_N=len(attrCount)\n",
    "                \n",
    "                for key in attrCount.keys():\n",
    "                    D_c_xi=curSubset[curSubset[attr]==key].shape[0]\n",
    "                    # calculate p(c,xi)\n",
    "                    self.args['bayes'][label][attr][key]=(D_c_xi+1)/(df.shape[0]+attr_N) \n",
    "                    \n",
    "                    for attr2 in dsct:\n",
    "                        if attr2 not in self.args['bayes'][label][attr]:\n",
    "                            self.args['bayes'][label][attr][attr2]={}\n",
    "                        \n",
    "                        attr2Count=df[attr2].value_counts()\n",
    "                        attr2_N=len(attr2Count)\n",
    "                        \n",
    "                        for key2 in attr2Count.keys():\n",
    "                            D_c_xi_xj=curSubset[(curSubset[attr]==key)&(curSubset[attr2]==key2)].shape[0]\n",
    "                            # calculate p(xj|c,xi)\n",
    "                            self.args['bayes'][label][attr][attr2][(key,key2)]=(D_c_xi_xj+1)/(D_c_xi+attr2_N)     \n",
    "        \n",
    "    def predict(self,test):\n",
    "        # Because continuous multiply may cause a problem of scalar vanishing, we adopt a log operation to avoid.\n",
    "        probs={}\n",
    "        total=test.shape[0]\n",
    "        for xi in range(total):\n",
    "            for label in self.args['labels'].keys():\n",
    "                curScore=0.0\n",
    "                for attr in self.args['dsct']:\n",
    "                    # p(c|xi)\n",
    "                    curScore+=np.log(self.args['bayes'][label][attr][test[attr].iloc[xi]])\n",
    "                        # p(xj|c,xi)\n",
    "                    for attr2 in self.args['dsct']:\n",
    "\n",
    "                        curScore+=np.log(self.args['bayes'][label][attr][attr2]\\\n",
    "                                         [(test[attr].iloc[xi],test[attr2].iloc[xi])])\n",
    "                \n",
    "                probs[label]=curScore\n",
    "\n",
    "        return probs\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': -46.15920157800021, '1': -25.41822571093543}\n"
     ]
    }
   ],
   "source": [
    "df,dsct,ctns=readWaterMelon()\n",
    "val_df=get_val_df(df.columns)\n",
    "model=AODE()\n",
    "model.train(df,dsct,ctns)\n",
    "print(model.predict(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1843977824369188e-11\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost ensemble with decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21\n"
     ]
    }
   ],
   "source": [
    "print(42/200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
